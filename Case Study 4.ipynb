{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Information\n",
    "\n",
    "Steel Plates Faults Data Set\n",
    "A dataset of steel plates' faults, classified into 7 different types. The goal was to train machine learning for automatic pattern recognition.\n",
    "\n",
    "The dataset consists of 27 features describing each fault (location, size, ...) and 7 binary features indicating the type of fault (on of 7: Pastry, Z_Scratch, K_Scatch, Stains, Dirtiness, Bumps, Other_Faults). The latter is commonly used as a binary classification target ('common' or 'other' fault.)\n",
    "\n",
    "- Attribute Information\n",
    "- V1: X_Minimum\n",
    "- V2: X_Maximum\n",
    "- V3: Y_Minimum\n",
    "- V4: Y_Maximum\n",
    "- V5: Pixels_Areas\n",
    "- V6: X_Perimeter\n",
    "- V7: Y_Perimeter\n",
    "- V8: Sum_of_Luminosity\n",
    "- V9: Minimum_of_Luminosity\n",
    "- V10: Maximum_of_Luminosity\n",
    "- V11: Length_of_Conveyer\n",
    "- V12: TypeOfSteel_A300\n",
    "- V13: TypeOfSteel_A400\n",
    "- V14: Steel_Plate_Thickness\n",
    "- V15: Edges_Index\n",
    "- V16: Empty_Index\n",
    "- V17: Square_Index\n",
    "- V18: Outside_X_Index\n",
    "- V19: Edges_X_Index\n",
    "- V20: Edges_Y_Index\n",
    "- V21: Outside_Global_Index\n",
    "- V22: LogOfAreas\n",
    "- V23: Log_X_Index\n",
    "- V24: Log_Y_Index\n",
    "- V25: Orientation_Index\n",
    "- V26: Luminosity_Index\n",
    "- V27: SigmoidOfAreas\n",
    "- V28: Pastry\n",
    "- V29: Z_Scratch\n",
    "- V30: K_Scatch\n",
    "- V31: Stains\n",
    "- V32: Dirtiness\n",
    "- V33: Bumps\n",
    "- Class: Other_Faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>270900</td>\n",
       "      <td>270944</td>\n",
       "      <td>267</td>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>24220</td>\n",
       "      <td>76</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>645</td>\n",
       "      <td>651</td>\n",
       "      <td>2538079</td>\n",
       "      <td>2538108</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>11397</td>\n",
       "      <td>84</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>-0.1756</td>\n",
       "      <td>0.2984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>829</td>\n",
       "      <td>835</td>\n",
       "      <td>1553913</td>\n",
       "      <td>1553931</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>7972</td>\n",
       "      <td>99</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.1228</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853</td>\n",
       "      <td>860</td>\n",
       "      <td>369370</td>\n",
       "      <td>369415</td>\n",
       "      <td>176</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>18996</td>\n",
       "      <td>99</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>-0.1568</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1289</td>\n",
       "      <td>1306</td>\n",
       "      <td>498078</td>\n",
       "      <td>498335</td>\n",
       "      <td>2409</td>\n",
       "      <td>60</td>\n",
       "      <td>260</td>\n",
       "      <td>246930</td>\n",
       "      <td>37</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9338</td>\n",
       "      <td>-0.1992</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     V1    V2       V3       V4    V5  V6   V7      V8  V9  V10  ...     V25  \\\n",
       "0    42    50   270900   270944   267  17   44   24220  76  108  ...  0.8182   \n",
       "1   645   651  2538079  2538108   108  10   30   11397  84  123  ...  0.7931   \n",
       "2   829   835  1553913  1553931    71   8   19    7972  99  125  ...  0.6667   \n",
       "3   853   860   369370   369415   176  13   45   18996  99  126  ...  0.8444   \n",
       "4  1289  1306   498078   498335  2409  60  260  246930  37  126  ...  0.9338   \n",
       "\n",
       "      V26     V27  V28  V29  V30  V31  V32  V33  Class  \n",
       "0 -0.2913  0.5822    1    0    0    0    0    0      1  \n",
       "1 -0.1756  0.2984    1    0    0    0    0    0      1  \n",
       "2 -0.1228  0.2150    1    0    0    0    0    0      1  \n",
       "3 -0.1568  0.5212    1    0    0    0    0    0      1  \n",
       "4 -0.1992  1.0000    1    0    0    0    0    0      1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steel = pd.read_csv('steel_fault.csv')\n",
    "steel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = steel.drop('Class', axis=1)\n",
    "y = steel['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original dataset, there are two classes to predict. First let us find out the optimal number of clusters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [KMeans(n_clusters=i).fit(X) for i in range(1,10)]\n",
    "cluster_var = [i.inertia_ for i in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the elbow\n",
    "plt.plot(K, cluster_var, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot we can see either 2 or 3 cluster would be appropriate for the data. Given what we know about the original classes, this seems about appropriate. Let us try clustering using two clusters. This way we can compare the clusters with the original class variable and see if they match up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = KMeans(n_clusters=2).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cluster = pd.Series(cluster.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1712\n",
       "0     229\n",
       "dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1268\n",
       "2     673\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-labelling the y_cluster data\n",
    "y_cluster = y_cluster.apply(lambda x: 1 if x==1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5703245749613601"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_cluster)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the above case we can see that the clustering model has about 57% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try a decision tree classifier with the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DecisionTreeClassifier()\n",
    "model1 = model1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model1.predict(php1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 100% on this data. The model may be over fitting. Let us try an ensemble bagging classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BaggingClassifier()\n",
    "model2 = model2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet again the classification yields very good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 33 independent features. We could also try dimensionality reduction by applying PCA on the data and trying if our classification yields similar results as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardise the data\n",
    "\n",
    "X_std = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix \n",
      "%s [[ 1.00051546  0.98882298  0.04184286 ...  0.07377766  0.10397756\n",
      "   0.22140961]\n",
      " [ 0.98882298  1.00051546  0.05217423 ...  0.06150319  0.09657306\n",
      "   0.20180749]\n",
      " [ 0.04184286  0.05217423  1.00051546 ... -0.06663543  0.06429539\n",
      "   0.1261862 ]\n",
      " ...\n",
      " [ 0.07377766  0.06150319 -0.06663543 ...  1.00051546 -0.03353481\n",
      "  -0.10036427]\n",
      " [ 0.10397756  0.09657306  0.06429539 ... -0.03353481  1.00051546\n",
      "  -0.08732287]\n",
      " [ 0.22140961  0.20180749  0.1261862  ... -0.10036427 -0.08732287\n",
      "   1.00051546]]\n"
     ]
    }
   ],
   "source": [
    "# covariance matrix\n",
    "cov_matrix = np.cov(X_std.T)\n",
    "print('Covariance Matrix \\n%s', cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigen Vectors \n",
      "%s [[-1.77993455e-01 -5.18645321e-02 -1.63806322e-02 ...  7.18342483e-01\n",
      "  -1.73355972e-04  8.91111629e-11]\n",
      " [-1.43921410e-01 -3.61416428e-02 -3.24718456e-02 ... -6.86343395e-01\n",
      "   1.65580597e-04 -8.51142563e-11]\n",
      " [ 9.06483684e-03  2.99543585e-02 -2.40027964e-01 ... -2.30144070e-04\n",
      "  -7.07104504e-01  3.63881754e-07]\n",
      " ...\n",
      " [-5.78497663e-02  1.80685469e-01  1.27257853e-01 ...  3.74729269e-04\n",
      "  -1.29608557e-07  6.65737292e-14]\n",
      " [-1.90006058e-02 -7.60783288e-02  1.35920479e-01 ...  2.17466399e-04\n",
      "  -1.05874692e-07  5.44604434e-14]\n",
      " [-1.03940337e-01  1.88717910e-02 -2.08660327e-01 ... -6.72912773e-05\n",
      "   3.56921505e-07 -1.83806072e-13]]\n",
      "\n",
      " Eigen Values \n",
      "%s [ 8.99906168e+00  3.73492802e+00  2.87826213e+00  2.37815435e+00\n",
      "  2.14050979e+00  1.84749992e+00  1.53112470e+00  1.34549367e+00\n",
      "  1.16774925e+00  9.92945964e-01  9.27079087e-01  7.79609766e-01\n",
      "  6.97254880e-01  6.35255571e-01  5.59081779e-01  4.89495197e-01\n",
      "  3.92888932e-01  3.50534629e-01  2.83652522e-01  2.35306650e-01\n",
      "  2.11897168e-01  1.79323788e-01  9.33387570e-02  5.54947445e-02\n",
      "  4.87945513e-02  4.23548444e-02  1.14753884e-02  6.70230153e-03\n",
      "  1.23777392e-03  4.90177921e-04  1.23232096e-05  2.92198456e-11\n",
      " -1.88606433e-16]\n"
     ]
    }
   ],
   "source": [
    "print('Eigen Vectors \\n%s', eig_vecs)\n",
    "print('\\n Eigen Values \\n%s', eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Variance Explained [ 27.25583448  38.56796716  47.28548006  54.4882956   60.97134714\n",
      "  66.56694742  71.20432883  75.27948179  78.81629278  81.82366975\n",
      "  84.63155296  86.99278966  89.10459468  91.02861979  92.72193416\n",
      "  94.20448874  95.39444788  96.45612677  97.31523703  98.02792012\n",
      "  98.66970193  99.21282739  99.49552639  99.66360564  99.81139174\n",
      "  99.93967363  99.97442962  99.99472916  99.99847805  99.99996268\n",
      " 100.         100.         100.        ]\n"
     ]
    }
   ],
   "source": [
    "tot = sum(eig_vals)\n",
    "var_exp = [( i /tot ) * 100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(\"Cumulative Variance Explained\", cum_var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cum_var_exp[cum_var_exp > 99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we can see that 99% of the variance is explained by the first 22 principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=22).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try the decision tree classifier again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca = DecisionTreeClassifier()\n",
    "model_pca = model_pca.fit(pca1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_pca.predict(pca1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the accuracy remains unchanged inspite of reduced number of features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
